{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6816a3b3-fb4e-448f-b3c5-7ef3713a31a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "from game import PendulumEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e95227-a41d-4ddc-9b48-5dd63ab591e4",
   "metadata": {},
   "source": [
    "# Weight Agnostic Neural Network (WAN)\n",
    "\n",
    "This code defines a Weight Agnostic Neural Network (WAN), which is a special type of neural network that uses mostly the same weight for its connections instead of learning many different weights.\n",
    "\n",
    "## Main Ideas:\n",
    "\n",
    "- The network has 5 input nodes, 10 hidden nodes, and 1 output node.\n",
    "- Instead of separate weights for every connection, it uses a few shared weights assigned to specific connections.\n",
    "- Each node applies a specific activation function like identity, sine, step, tanh, or others to process the input.\n",
    "- When given an input state (a list of 5 numbers), the network:\n",
    "  1. Sets the first node to 1 (bias), next nodes to the input values.\n",
    "  2. Calculates the values of other nodes by multiplying inputs by the shared weights and applying the node’s activation function.\n",
    "  3. Returns the output node’s value as the network’s action or output.\n",
    "- You can change the shared weight value or use predefined weights to see how the network behaves differently.\n",
    "\n",
    "## Why is this important?\n",
    "\n",
    "WANs show that the structure of the network and types of node functions can be more important than having many different weights. This approach helps create robust networks that don’t rely heavily on tuning individual weights.\n",
    "\n",
    "---\n",
    "\n",
    "**In short:**  \n",
    "A WAN uses mostly shared weights and focuses on how the network is built and how nodes transform signals, rather than on learning many different weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194a571c-98a8-4306-9f57-fcb20e6036b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WAN(object):  #Weight Agnostic Neural\n",
    "    def __init__(self, init_shared_weight):\n",
    "        self.num_hidden = 10\n",
    "        self.input_size = 5\n",
    "        self.output_size = 1\n",
    "        self.shape_in = [self.input_size, self.num_hidden]\n",
    "        self.shape_out = [self.num_hidden, self.output_size]\n",
    "        self.aVec = [1,1,1,1,1,1,7,7,5,1,5,5,4,1,7,3,9,1,3,7,9,5,4,3,9,7,1,7,1]\n",
    "        self.wKey = [10,35,36,41,64,69,95,97,108,125,128,142,157,202,231,257,289,302,331,361,362,363,364,367,368,373,374,376,394,395,398,401,403,425,461,484,517,543,574,576,602,603,604,606,633,662,692,722,723,753,782,811]\n",
    "        self.weights = [-0.1783,-0.0303,1.5435,1.8088,-0.857,1.024,-0.3872,0.2639,-1.138,-0.2857,0.3797,-0.199,1.3008,-1.4126,-1.3841,7.1232,-1.5903,-0.6301,0.8013,-1.1348,-0.7306,0.006,1.4754,1.1144,-1.5251,-1.277,1.0933,0.1666,-0.5483,2.6779,-1.2728,0.4593,-0.2608,0.1183,-2.1036,-0.3119,-1.0469,0.2662,0.7156,0.0328,0.3441,-0.1147,-0.0553,-0.4123,-3.2276,2.5201,1.7362,-2.9654,0.9641,-1.7355,-0.1573,2.9135]\n",
    "        self.weight_bias = -1.5\n",
    "        nNodes = len(self.aVec)\n",
    "        self.wVec = [0] * (nNodes*nNodes)\n",
    "        for i in range(nNodes*nNodes):\n",
    "            self.wVec[i] = 0\n",
    "        self.set_weight(init_shared_weight, 0)\n",
    "\n",
    "    def set_weight(self, weight, weight_bias):\n",
    "        nValues = len(self.wKey)\n",
    "        if type(weight_bias).__name__ not in ['int','long','float']:\n",
    "            weight_bias = 0\n",
    "        if type(weight).__name__ == 'list':\n",
    "            weights = weight\n",
    "        else:\n",
    "            weights = [weight] * nValues\n",
    "        for i in range(nValues):\n",
    "            k = self.wKey[i]\n",
    "            self.wVec[k] = weights[i] + weight_bias\n",
    "\n",
    "    def tune_weights(self):\n",
    "        self.set_weight(self.weights, self.weight_bias)\n",
    "\n",
    "    def get_action(self, old_state):\n",
    "        nNodes = len(self.aVec)\n",
    "        wMat = np.array(self.wVec).reshape((nNodes, nNodes))\n",
    "        nodeAct = [0] * nNodes\n",
    "        nodeAct[0] = 1\n",
    "        for i in range(len(old_state)):\n",
    "            nodeAct[i+1] = old_state[i]\n",
    "        for iNode in range(self.input_size+1, nNodes):\n",
    "            rawAct = np.dot(nodeAct, wMat[:, iNode:iNode+1])  #TPJ\n",
    "            rawAct = self.applyActSimple(self.aVec[iNode], rawAct.tolist()[0])\n",
    "            nodeAct[iNode] = rawAct\n",
    "        return nodeAct[-self.output_size:][0]\n",
    "\n",
    "    def applyActSimple(self, actId, x):\n",
    "        if actId == 1:\n",
    "            return x\n",
    "        elif actId == 2:\n",
    "            return 0.0 if x<=0.0 else 1.0  #unsigned step\n",
    "        elif actId == 3:\n",
    "            return math.sin(math.pi*x)\n",
    "        elif actId == 4:\n",
    "            return math.exp(-(x*x)/2.0)  #gaussian with mean zero and unit variance 1\n",
    "        elif actId == 5:\n",
    "            return math.tanh(x)\n",
    "        elif actId == 6:\n",
    "            return (math.tanh(x/2.0) + 1.0)/2.0  #sigmoid\n",
    "        elif actId == 7:\n",
    "            return -x\n",
    "        elif actId == 8:\n",
    "            return math.abs(x)\n",
    "        elif actId == 9:\n",
    "            return max(x, 0)  #relu\n",
    "        elif actId == 10:\n",
    "            return math.cos(math.pi*x)\n",
    "        else:\n",
    "            print('unsupported actionvation type: ',actId)\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09fcb82-b42a-4ff9-a3a7-ec941b2c9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wan():\n",
    "    environment = PendulumEnv()\n",
    "    drl = WAN(-1.5)\n",
    "    for epoch in range(20):\n",
    "        if epoch == 0:\n",
    "            print('init_weights:')\n",
    "        elif epoch == 10:\n",
    "            print()\n",
    "            print('tune_weights:')\n",
    "            drl.tune_weights()\n",
    "\n",
    "        state_old = environment.reset()\n",
    "        rewards = 1\n",
    "        for step in range(2000):\n",
    "            environment.render()\n",
    "            action_now = drl.get_action(state_old)\n",
    "            state_new, reward_now, done, _ = environment.step(action_now)\n",
    "            if done:\n",
    "                reward_now = -1\n",
    "                break\n",
    "            rewards += reward_now\n",
    "            state_old = state_new\n",
    "        print('epoch=%04d'%(epoch),'  ','rewards=%d'%(rewards),'  ','step=%d'%(step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b30b4c7-60b2-4eed-9fca-1cc123ebd533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANN\n",
      "init_weights:\n",
      "epoch=0000    rewards=-1359    step=1999\n",
      "epoch=0001    rewards=-1428    step=1999\n",
      "epoch=0002    rewards=-1157    step=1999\n",
      "epoch=0003    rewards=-1333    step=1999\n",
      "epoch=0004    rewards=-1227    step=1999\n",
      "epoch=0005    rewards=-1316    step=1999\n",
      "epoch=0006    rewards=-1397    step=1999\n",
      "epoch=0007    rewards=-1102    step=1999\n",
      "epoch=0008    rewards=-1324    step=1999\n",
      "epoch=0009    rewards=-1349    step=1999\n",
      "\n",
      "tune_weights:\n",
      "epoch=0010    rewards=-1137    step=1999\n",
      "epoch=0011    rewards=-1321    step=1999\n",
      "epoch=0012    rewards=-1247    step=1999\n",
      "epoch=0013    rewards=-1133    step=1999\n",
      "epoch=0014    rewards=-1206    step=1999\n",
      "epoch=0015    rewards=-1158    step=1999\n",
      "epoch=0016    rewards=-1189    step=1999\n",
      "epoch=0017    rewards=-1216    step=1999\n",
      "epoch=0018    rewards=-1188    step=1999\n",
      "epoch=0019    rewards=-59    step=20\n"
     ]
    }
   ],
   "source": [
    "env = PendulumEnv()\n",
    "print(\"WANN\")\n",
    "wan()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd2135-159d-47a0-8d6b-96e20981ee55",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Setup:**  \n",
    "  The WAN uses a fixed network architecture with predefined connection patterns and activation types. The weights are initially set and then optionally tuned during training.\n",
    "\n",
    "- **Training Process:**  \n",
    "  - Runs for 20 epochs, with weight tuning starting at epoch 10.  \n",
    "  - The controller generates actions based on the current state without explicit learning from rewards, relying on the fixed/tuned weights.\n",
    "    \n",
    "\n",
    "- **Results:**  \n",
    "  - The initial weights allow the pendulum to survive close to the maximum number of steps (around 2000), though rewards remain negative.  \n",
    "  - After tuning weights, some improvement is seen in terms of fewer early failures (higher rewards and fewer early terminations in some epochs).  \n",
    "  - Performance is more consistent than DRL but still far from perfect control."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
